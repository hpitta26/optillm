services:
  &name optillm:
    build:
      context: https://github.com/codelion/optillm.git#main
      # context: .
      dockerfile: Dockerfile
      tags:
        - optillm:latest
      args:
        - PORT=${OPTILLM_PORT:-8000}
    image: optillm:latest
    container_name: *name
    hostname: *name
    ports:
      - "${OPTILLM_PORT:-8000}:${OPTILLM_PORT:-8000}"
    env_file:
      - .env
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY:-""}
      OPTILLM_PORT: ${OPTILLM_PORT:-8000}
      # OPTILLM_BASE_URL: ${OPENAI_BASE_URL:-"https://openrouter.ai/api/v1"} # can be set to any OpenAI API compatible endpoint
      # OPTILLM_API_KEY: ${OPTILLM_API_KEY:-} # optionally sets an API key for Optillm clients
      # Uncomment and set values for other arguments (prefixed with OPTILLM_) as needed, e.g.:
      # OPTILLM_APPROACH: auto
      # OPTILLM_MODEL: gpt-4o-mini
      # OPTILLM_SIMULATIONS: 2
      # OPTILLM_EXPLORATION: 0.2
      # OPTILLM_DEPTH: 1
      # OPTILLM_BEST_OF_N: 3
      # OPTILLM_RSTAR_MAX_DEPTH: 3
      # OPTILLM_RSTAR_NUM_ROLLOUTS: 5
      # OPTILLM_RSTAR_C: 1.4
      # OPTILLM_N: 1
      # OPTILLM_RETURN_FULL_RESPONSE: false
    restart: on-failure
    stop_grace_period: 2s
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:${OPTILLM_PORT:-8000}/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 3s
